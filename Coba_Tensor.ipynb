{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coba Tensor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SokKanaTorajd/nlp-practices/blob/main/Coba_Tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTl7-PolZ7Iy"
      },
      "source": [
        "# !pip uninstall tensorflow\n",
        "# !pip install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPvkwRq3bEK9"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npvC4BPIaD3_"
      },
      "source": [
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import math\n",
        "import operator\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_colwidth', 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuvaN49babrL",
        "outputId": "277001a9-490a-453c-ae2c-47143b6957a3"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPpNrNAzcGGp",
        "outputId": "1542d529-cae4-4327-f546-dcb0a5f4faed"
      },
      "source": [
        "x = tf.random.uniform([3, 3])\n",
        "\n",
        "print(\"Is there a GPU available: \"),\n",
        "print(tf.test.is_gpu_available())\n",
        "\n",
        "print(\"Is the Tensor on GPU #0:  \"),\n",
        "print(x.device.endswith('GPU:0'))\n",
        "\n",
        "print(\"Device name: {}\".format((x.device)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is there a GPU available: \n",
            "WARNING:tensorflow:From <ipython-input-5-2f39aec4b35c>:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "True\n",
            "Is the Tensor on GPU #0:  \n",
            "True\n",
            "Device name: /job:localhost/replica:0/task:0/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ERU3G3Vcu0K",
        "outputId": "56d2d9bf-772c-450e-bf2f-a3f92088d089"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvVl5_E0UBsv",
        "outputId": "60497733-6dc3-419b-a38c-8a0bfa3fad53"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'drive': Transport endpoint is not connected\n",
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWvplAO4c4sf",
        "outputId": "e9cdee69-850e-4f25-c566-8f340a6483fe"
      },
      "source": [
        "cd gdrive/MyDrive/Colab\\ Notebooks/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4CmrGokcJTr"
      },
      "source": [
        "import pandas as pd\n",
        "df  = pd.read_csv(\"Indonesian Sentiment Twitter Dataset Labeled-Ok.csv\")\n",
        "df_test  = pd.read_csv(\"Unlabeled.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iyOFK6kc9_2"
      },
      "source": [
        "X_train, X_test  = train_test_split(df, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMK_wTBvdDHY"
      },
      "source": [
        "y_train, y_test = X_train['sentimen'].values, X_test['sentimen'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlnrm0fFdqFK"
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 100 # max number of words in a question to use"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw2NHHmddG9x"
      },
      "source": [
        "X_train = X_train['Tweet'].fillna('_NA_').values\n",
        "X_test = X_test['Tweet'].fillna('_NA_').values\n",
        "# X_submission = df_test['Tweet'].fillna('_NA_').values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpglC7Vtdkob",
        "outputId": "188c735c-8883-4ad1-ad13-300d6f8a13c2"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9725,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPdoWWqpeYag"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "# X_submission = tokenizer.texts_to_sequences(X_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-Y_JD6tecD3"
      },
      "source": [
        "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
        "# X_submission = pad_sequences(X_submission, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg9TshnBefJs"
      },
      "source": [
        "# def data_prep(df):\n",
        "#     print(\"Splitting dataframe with shape {} into training and test datasets\".format(df.shape))\n",
        "#     X_train, X_test  = train_test_split(df, test_size=0.1, random_state=2019)\n",
        "#     y_train, y_test = X_train['target'].values, X_test['target'].values\n",
        "    \n",
        "#     print(\"Filling missing values\")\n",
        "#     X_train = X_train['Tweet'].fillna('_NA_').values\n",
        "#     X_test = X_test['Tweet'].fillna('_NA_').values\n",
        "#     X_submission = df_test['Tweet'].fillna('_NA_').values\n",
        "    \n",
        "#     print(\"Tokenizing {} questions into words\".format(df.shape[0]))\n",
        "#     tokenizer = Tokenizer(num_words=max_features)\n",
        "#     tokenizer.fit_on_texts(list(X_train))\n",
        "#     X_train = tokenizer.texts_to_sequences(X_train)\n",
        "#     X_test = tokenizer.texts_to_sequences(X_test)\n",
        "#     X_submission = tokenizer.texts_to_sequences(X_submission)\n",
        "    \n",
        "#     print(\"Padding sequences for uniform dimensions\")\n",
        "#     X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "#     X_test = pad_sequences(X_test, maxlen=maxlen)\n",
        "#     X_submission = pad_sequences(X_submission, maxlen=maxlen)\n",
        "    \n",
        "#     print(\"Completed data preparation, returning training, test and submission datasets, split as dependent(X) and independent(Y) variables\")\n",
        "    \n",
        "#     return X_train, X_test, y_train, y_test, X_submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PU1WjKHu-5y"
      },
      "source": [
        "# X_train, X_test, y_train, y_test, X_submission = data_prep(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzpLZgtCejXL",
        "outputId": "dca9d80e-7adc-441f-83c3-0ee1770b5bb4"
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
        "model1.add(Bidirectional(CuDNNLSTM(128, return_sequences=True)))\n",
        "model1.add(GlobalMaxPool1D())\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(64, activation='relu'))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(32, activation='relu'))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100, 256)          440320    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 15,458,881\n",
            "Trainable params: 15,458,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8xCCOu3emi6",
        "outputId": "1e4a4f88-763d-4998-a7b0-f0c251212780"
      },
      "source": [
        "%time model1.fit(X_train, y_train, batch_size=512, epochs=5, validation_data=(X_test, y_test), verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "19/19 [==============================] - 6s 188ms/step - loss: 0.1975 - accuracy: 0.4845 - val_loss: -0.3703 - val_accuracy: 0.5032\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 3s 152ms/step - loss: -0.3971 - accuracy: 0.4918 - val_loss: -0.6544 - val_accuracy: 0.5032\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 3s 155ms/step - loss: -1.2319 - accuracy: 0.4918 - val_loss: -2.5126 - val_accuracy: 0.5032\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 3s 151ms/step - loss: -8.4475 - accuracy: 0.4918 - val_loss: -8.8609 - val_accuracy: 0.5032\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 3s 151ms/step - loss: -27.9243 - accuracy: 0.4918 - val_loss: -23.1804 - val_accuracy: 0.5032\n",
            "CPU times: user 13.1 s, sys: 618 ms, total: 13.7 s\n",
            "Wall time: 18 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f959fcdce10>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr1ajP0KeseR"
      },
      "source": [
        "def build_vocab(texts):\n",
        "    sentences = texts.apply(lambda x: x.split()).values\n",
        "    vocab = {}\n",
        "    for sentence in sentences:\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except KeyError:\n",
        "                vocab[word] = 1\n",
        "    return vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmRgm0hazda9"
      },
      "source": [
        "def check_coverage(vocab, embeddings_index):\n",
        "    known_words = {}\n",
        "    unknown_words = {}\n",
        "    nb_known_words = 0\n",
        "    nb_unknown_words = 0\n",
        "    for word in vocab.keys():\n",
        "        try:\n",
        "            known_words[word] = embeddings_index[word]\n",
        "            nb_known_words += vocab[word]\n",
        "        except:\n",
        "            unknown_words[word] = vocab[word]\n",
        "            nb_unknown_words += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print('Found embeddings for {:.2%} of vocab'.format(len(known_words) / len(vocab)))\n",
        "    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
        "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return unknown_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8vl5QNcz2zT"
      },
      "source": [
        "vocab = build_vocab(df['Tweet'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vulp7Br90nHp"
      },
      "source": [
        "def load_embed(file):\n",
        "    def get_coefs(word,*arr): \n",
        "        return word, np.asarray(arr, dtype='float32')\n",
        "    \n",
        "    if file == '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec':\n",
        "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding=\"utf8\") if len(o)>100)\n",
        "    else:\n",
        "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
        "        \n",
        "    return embeddings_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqnky9Fdz7Wd",
        "outputId": "ff7df6be-1eaf-439c-d926-d8122a32c51a"
      },
      "source": [
        "glove = 'glove_wiki_id_50.txt'\n",
        "\n",
        "print(\"Extracting GloVe embedding\")\n",
        "embed_glove = load_embed(glove)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting GloVe embedding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZRYwH3e0ga5",
        "outputId": "f090882e-15c4-4062-d1b6-e5087c978660"
      },
      "source": [
        "print(\"Glove : \")\n",
        "oov_glove = check_coverage(vocab, embed_glove)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Glove : \n",
            "Found embeddings for 48.49% of vocab\n",
            "Found embeddings for  82.76% of all text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v8fVis20vM7",
        "outputId": "b0ee4d6e-c083-455f-fbdb-1a9a72787a57"
      },
      "source": [
        "type(embed_glove)\n",
        "dict(list(embed_glove.items())[20:22])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Indonesia': array([ 5.9440e-03,  7.0470e-03, -3.5600e-04,  9.0490e-03, -9.1120e-03,\n",
              "        -7.5050e-03, -8.8590e-03,  4.6680e-03, -2.2780e-03, -2.6630e-03,\n",
              "         2.8650e-03, -7.5980e-03,  2.2630e-03, -8.7430e-03,  1.9200e-03,\n",
              "        -6.6060e-03,  5.4140e-03,  5.2000e-05, -5.9670e-03, -2.8960e-03,\n",
              "        -8.8280e-03,  9.4330e-03, -4.6000e-04,  4.0110e-03, -1.1350e-02,\n",
              "        -6.1500e-03, -1.5989e-02, -6.7670e-03,  5.0100e-03,  1.6000e-03,\n",
              "         7.9230e-03, -1.5841e-02, -1.1521e-02,  1.8191e-02,  9.1500e-04,\n",
              "        -1.9600e-03,  1.3045e-02,  7.4020e-03, -1.3450e-03,  2.9710e-03,\n",
              "        -6.4790e-03,  6.8580e-03,  5.9980e-03, -7.9770e-03,  1.5070e-02,\n",
              "        -1.8128e-02, -3.8260e-03,  3.2060e-03, -1.0293e-02, -7.3240e-03],\n",
              "       dtype=float32),\n",
              " 'Pada': array([ 0.001962, -0.007293, -0.018094,  0.009985,  0.01025 ,  0.013142,\n",
              "        -0.007931, -0.011334,  0.010864,  0.008238, -0.007061,  0.011391,\n",
              "         0.014036,  0.002048,  0.002705,  0.003668, -0.00704 ,  0.003804,\n",
              "         0.008052, -0.006796,  0.006111, -0.005641, -0.008872,  0.0083  ,\n",
              "        -0.00123 ,  0.002375,  0.002972, -0.011954,  0.007839, -0.006084,\n",
              "         0.000803, -0.002214,  0.008226,  0.006278, -0.011766, -0.004093,\n",
              "         0.009222, -0.013068, -0.013193, -0.018707, -0.015714,  0.009433,\n",
              "        -0.019161, -0.000716, -0.000867,  0.009772,  0.003372,  0.000458,\n",
              "        -0.005584, -0.006857], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnWN5aqi1DHb"
      },
      "source": [
        "Lower Casing Teks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCZQvX1n073u"
      },
      "source": [
        "df['processed_tweet'] = df['Tweet'].apply(lambda x: x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7JOy9Jh1NNV"
      },
      "source": [
        "vocab_low = build_vocab(df['processed_tweet'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1yScchL17aa",
        "outputId": "826b13f8-c575-44d3-b1a8-87783d9a0d34"
      },
      "source": [
        "print(\"Glove : \")\n",
        "oov_glove = check_coverage(vocab_low, embed_glove)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Glove : \n",
            "Found embeddings for 47.81% of vocab\n",
            "Found embeddings for  82.75% of all text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS8jA51n1-z4",
        "outputId": "d11f13a0-3da6-4f36-d65d-12e03e1f1374"
      },
      "source": [
        "oov_glove[1:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 197),\n",
              " ('3', 138),\n",
              " ('tengok', 136),\n",
              " ('i', 131),\n",
              " ('giveaway', 115),\n",
              " ('a', 113),\n",
              " ('mcm', 104),\n",
              " ('d', 94),\n",
              " ('hahaha', 92),\n",
              " ('k', 92),\n",
              " ('t', 89),\n",
              " ('korang', 88),\n",
              " ('m', 79),\n",
              " ('b', 77),\n",
              " ('wkwk', 75),\n",
              " ('4', 75),\n",
              " ('gimana', 73),\n",
              " ('haha', 72),\n",
              " ('5', 72)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6jVwLRM2BxA"
      },
      "source": [
        "def add_lower(embedding, vocab):\n",
        "    count = 0\n",
        "    for word in vocab:\n",
        "        if word in embedding and word.lower() not in embedding:  \n",
        "            embedding[word.lower()] = embedding[word]\n",
        "            count += 1\n",
        "    print(f\"Added {count} words to embedding\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdelGxRy2JOo",
        "outputId": "ecda8e44-e670-40eb-d4fe-ae1d6f902290"
      },
      "source": [
        "print(\"Glove : \")\n",
        "add_lower(embed_glove, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Glove : \n",
            "Added 44 words to embedding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfvsJLaN2LsB",
        "outputId": "bc894565-6148-4f25-b983-1af5a57893d3"
      },
      "source": [
        "print(\"Glove : \")\n",
        "oov_glove = check_coverage(vocab_low, embed_glove)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Glove : \n",
            "Found embeddings for 48.00% of vocab\n",
            "Found embeddings for  82.96% of all text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yizuZp2t5HX0"
      },
      "source": [
        "Removing special character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ7XRLYz4jBH"
      },
      "source": [
        "punctuations = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Gw8bK_5QFj"
      },
      "source": [
        "def clean_text(x):\n",
        "\n",
        "    x = str(x)\n",
        "    for punct in \"/-'\":\n",
        "        x = x.replace(punct, ' ')\n",
        "    for punct in punctuations:\n",
        "        x = x.replace(punct, '')\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk5wSwQ85SaC",
        "outputId": "4ed0f3ef-331a-476f-b631-c7a20486561f"
      },
      "source": [
        "df[\"processed_tweet\"] = df[\"processed_tweet\"].progress_apply(lambda x: clean_text(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10806/10806 [00:00<00:00, 75982.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIfbo3zA5W6n"
      },
      "source": [
        "vocab_low = build_vocab(df['processed_tweet'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROSTd19b5jJr",
        "outputId": "2035ef9d-f547-4b37-88eb-02b9bc27a02e"
      },
      "source": [
        "print(\"Glove : \")\n",
        "oov_glove = check_coverage(vocab_low, embed_glove)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Glove : \n",
            "Found embeddings for 48.31% of vocab\n",
            "Found embeddings for  83.05% of all text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iENulnoe5kfv"
      },
      "source": [
        "df['Tweet'] = df['processed_tweet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEhWIhSb6X3H"
      },
      "source": [
        "def data_prep(df):\n",
        "    print(\"Splitting dataframe with shape {} into training and test datasets\".format(df.shape))\n",
        "    X_train, X_test  = train_test_split(df, test_size=0.1, random_state=2019)\n",
        "    y_train, y_test = X_train['sentimen'].values, X_test['sentimen'].values\n",
        "    \n",
        "    print(\"Filling missing values\")\n",
        "    X_train = X_train['Tweet'].fillna('_NA_').values\n",
        "    X_test = X_test['Tweet'].fillna('_NA_').values\n",
        "    # X_submission = df_test['Tweet'].fillna('_NA_').values\n",
        "    \n",
        "    print(\"Tokenizing {} Tweet into words\".format(df.shape[0]))\n",
        "    tokenizer = Tokenizer(num_words=max_features)\n",
        "    tokenizer.fit_on_texts(list(X_train))\n",
        "    X_train = tokenizer.texts_to_sequences(X_train)\n",
        "    X_test = tokenizer.texts_to_sequences(X_test)\n",
        "    # X_submission = tokenizer.texts_to_sequences(X_submission)\n",
        "    \n",
        "    print(\"Padding sequences for uniform dimensions\")\n",
        "    X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "    X_test = pad_sequences(X_test, maxlen=maxlen)\n",
        "    # X_submission = pad_sequences(X_submission, maxlen=maxlen)\n",
        "    \n",
        "    print(\"Completed data preparation, returning training, test and submission datasets, split as dependent(X) and independent(Y) variables\")\n",
        "    # return X_train, X_test, y_train, y_test, X_submission\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMH20fRh5vpr",
        "outputId": "4a72aed5-d426-4ed4-814c-bc2c48678d2e"
      },
      "source": [
        "X_train, X_test, y_train, y_test = data_prep(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting dataframe with shape (10806, 3) into training and test datasets\n",
            "Filling missing values\n",
            "Tokenizing 10806 Tweet into words\n",
            "Padding sequences for uniform dimensions\n",
            "Completed data preparation, returning training, test and submission datasets, split as dependent(X) and independent(Y) variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWf0kbtXU3-S",
        "outputId": "b0c82f95-0319-471b-d352-358d5680fb15"
      },
      "source": [
        "# embeddings_index = {}\n",
        "# f = open(os.path.join('glove_wiki_id_50.txt'))\n",
        "# for line in f:\n",
        "#     values = line.split()\n",
        "#     word = values[0]\n",
        "#     coefs = np.asarray(values[1:], dtype='float32')\n",
        "#     embeddings_index[word] = coefs\n",
        "# f.close()\n",
        "\n",
        "# print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 212550 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "C1RcmRGvUjTR",
        "outputId": "a623f264-cfc4-4a94-bc23-d64deb33a66f"
      },
      "source": [
        "# EMBEDDING_DIM = 50\n",
        "# embedding_matrix = np.zeros((len(embed_glove) + 1, EMBEDDING_DIM))\n",
        "# for word, i in embed_glove.items():\n",
        "#     print (i)\n",
        "#     embedding_vector = embeddings_index.get(word)\n",
        "#     if embedding_vector is not None:\n",
        "#         # words not found in embedding index will be all-zeros.\n",
        "#         embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.015828  0.000282  0.0022    0.007403  0.004672  0.015625  0.006509\n",
            "  0.013281  0.009538  0.007392 -0.001099 -0.003191 -0.013885  0.011943\n",
            "  0.011973 -0.004197  0.007191  0.005189 -0.012265  0.0101   -0.002079\n",
            "  0.000253  0.008111  0.006362 -0.001157  0.013243  0.000835 -0.007282\n",
            "  0.005522  0.009601  0.008059 -0.006037  0.01209   0.002687 -0.004104\n",
            " -0.003712  0.008948  0.005749 -0.011684 -0.005787  0.000122  0.008251\n",
            "  0.009211  0.007168  0.004828  0.002199  0.012714  0.016136  0.009771\n",
            " -0.01227 ]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-c6eeb9e80f5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# words not found in embedding index will be all-zeros.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "rR1Ixwv66kbG",
        "outputId": "3926ba3b-41dc-4873-ecf9-05909b4a885c"
      },
      "source": [
        "embed_size = 50 # how big is each word vector\n",
        "max_features = 212594 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 100 # max number of words in a tweet to use\n",
        "\n",
        "list_weight = [[0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1]]\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(max_features, embed_size, input_length=maxlen, weights = list_weight))\n",
        "model1.add(Bidirectional(CuDNNLSTM(128, return_sequences=True)))\n",
        "model1.add(GlobalMaxPool1D())\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(64, activation='relu'))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(32, activation='relu'))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-fa85d681434a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCuDNNLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGlobalMaxPool1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    200\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2668\u001b[0m         \u001b[0;31m# Using `init_scope` since we want variable assignment in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# `set_weights` to be treated like variable initialization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2670\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2671\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1782\u001b[0m           \u001b[0;34m'with a weight list of length %s, but the layer was '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m           \u001b[0;34m'expecting %s weights. Provided weights: %s...'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m           (self.name, len(weights), expected_num_weights, str(weights)[:50]))\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0mweight_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"embedding_17\" with a weight list of length 2, but the layer was expecting 1 weights. Provided weights: [[0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1]]..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alo51H4JCtqG",
        "outputId": "53a28ecb-e26a-47ee-caf6-a7623abc8c04"
      },
      "source": [
        "print(embed_glove['dan'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.015828  0.000282  0.0022    0.007403  0.004672  0.015625  0.006509\n",
            "  0.013281  0.009538  0.007392 -0.001099 -0.003191 -0.013885  0.011943\n",
            "  0.011973 -0.004197  0.007191  0.005189 -0.012265  0.0101   -0.002079\n",
            "  0.000253  0.008111  0.006362 -0.001157  0.013243  0.000835 -0.007282\n",
            "  0.005522  0.009601  0.008059 -0.006037  0.01209   0.002687 -0.004104\n",
            " -0.003712  0.008948  0.005749 -0.011684 -0.005787  0.000122  0.008251\n",
            "  0.009211  0.007168  0.004828  0.002199  0.012714  0.016136  0.009771\n",
            " -0.01227 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTt9fqB767oc"
      },
      "source": [
        "print(embed_glove.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgSlreBBJnvP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L55gUELuaqtg"
      },
      "source": [
        "==============================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb0cRmmmbHFs"
      },
      "source": [
        "corpus = [\n",
        "    # Positive Reviews\n",
        "\n",
        "    'This is an excellent movie',\n",
        "    'The move was fantastic I like it',\n",
        "    'You should watch it is brilliant',\n",
        "    'Exceptionally good',\n",
        "    'Wonderfully directed and executed I like it',\n",
        "    'Its a fantastic series',\n",
        "    'Never watched such a brillent movie',\n",
        "    'It is a Wonderful movie',\n",
        "\n",
        "    # Negtive Reviews\n",
        "\n",
        "    \"horrible acting\",\n",
        "    'waste of money',\n",
        "    'pathetic picture',\n",
        "    'It was very boring',\n",
        "    'I did not like the movie',\n",
        "    'The movie was horrible',\n",
        "    'I will not recommend',\n",
        "    'The acting is pathetic'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2renqdvbPOv"
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxAFAKMOasXs"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('glove_wiki_id_50.txt', encoding=\"utf8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocpQ1m5ebY4i"
      },
      "source": [
        "sentiments = array([1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w4pnsHpbzAh",
        "outputId": "8012b53d-0d35-4755-eeed-19ca4d2f1eaa"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "all_words = []\n",
        "for sent in corpus:\n",
        "    tokenize_word = word_tokenize(sent)\n",
        "    for word in tokenize_word:\n",
        "        all_words.append(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99F8p6nQcAcK",
        "outputId": "75c33bed-2de4-45f0-9190-ba7f62851204"
      },
      "source": [
        "unique_words = set(all_words)\n",
        "print(len(unique_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je9zuh43cEg6",
        "outputId": "3490dc94-7547-4a2d-9cfa-5ab2a0f0e459"
      },
      "source": [
        "vocab_length = 100\n",
        "embedded_sentences = [one_hot(sent, vocab_length) for sent in corpus]\n",
        "print(embedded_sentences )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11, 48, 61, 81, 47], [7, 79, 43, 31, 15, 79, 13], [4, 6, 28, 13, 48, 54], [67, 54], [80, 74, 63, 12, 15, 79, 13], [26, 49, 31, 61], [55, 15, 43, 49, 64, 47], [13, 48, 49, 34, 47], [6, 87], [89, 12, 42], [19, 53], [13, 43, 55, 21], [15, 95, 98, 79, 7, 47], [7, 47, 43, 6], [15, 44, 98, 41], [7, 87, 48, 19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXDEVY7gdM9A"
      },
      "source": [
        "word_count = lambda sentence: len(word_tokenize(sentence))\n",
        "longest_sentence = max(corpus, key=word_count)\n",
        "length_long_sentence = len(word_tokenize(longest_sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72x2i_QOdsFT",
        "outputId": "8b6df8ef-3320-4c0b-d9e1-62e1d8efd46e"
      },
      "source": [
        "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\n",
        "print(padded_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11 48 61 81 47  0  0]\n",
            " [ 7 79 43 31 15 79 13]\n",
            " [ 4  6 28 13 48 54  0]\n",
            " [67 54  0  0  0  0  0]\n",
            " [80 74 63 12 15 79 13]\n",
            " [26 49 31 61  0  0  0]\n",
            " [55 15 43 49 64 47  0]\n",
            " [13 48 49 34 47  0  0]\n",
            " [ 6 87  0  0  0  0  0]\n",
            " [89 12 42  0  0  0  0]\n",
            " [19 53  0  0  0  0  0]\n",
            " [13 43 55 21  0  0  0]\n",
            " [15 95 98 79  7 47  0]\n",
            " [ 7 47 43  6  0  0  0]\n",
            " [15 44 98 41  0  0  0]\n",
            " [ 7 87 48 19  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMFtV2EodvLf"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_length, 20, input_length=length_long_sentence))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3Tbyyn6d0Oi",
        "outputId": "9a5a8bf6-4428-47c3-e5fe-6d958df769d9"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, 7, 20)             2000      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 140)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 141       \n",
            "=================================================================\n",
            "Total params: 2,141\n",
            "Trainable params: 2,141\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjetbhgAePOB",
        "outputId": "d9c3d596-98e8-4997-8c81-d633dd4ca23f"
      },
      "source": [
        "model.fit(padded_sentences, sentiments, epochs=2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.6892 - acc: 0.7500\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6854 - acc: 0.7500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f956e397650>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJKIMCGBeSCq",
        "outputId": "cc8df3aa-1396-4dc3-b617-b272838b75d7"
      },
      "source": [
        "loss, accuracy = model.evaluate(padded_sentences, sentiments, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP5L8kpLeVaM"
      },
      "source": [
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkcfJpMRegq-"
      },
      "source": [
        "vocab_length = len(word_tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGkFd9rZemXS",
        "outputId": "6a4678ac-1bdc-49db-ead5-4769d7b9585b"
      },
      "source": [
        "embedded_sentences = word_tokenizer.texts_to_sequences(corpus)\n",
        "print(embedded_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[14, 3, 15, 16, 1], [4, 17, 6, 9, 5, 7, 2], [18, 19, 20, 2, 3, 21], [22, 23], [24, 25, 26, 27, 5, 7, 2], [28, 8, 9, 29], [30, 31, 32, 8, 33, 1], [2, 3, 8, 34, 1], [10, 11], [35, 36, 37], [12, 38], [2, 6, 39, 40], [5, 41, 13, 7, 4, 1], [4, 1, 6, 10], [5, 42, 13, 43], [4, 11, 3, 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2OwU2faesd9",
        "outputId": "dfcd5e71-b45d-4d98-b974-8128843e48f5"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "word_count = lambda sentence: len(word_tokenize(sentence))\n",
        "longest_sentence = max(corpus, key=word_count)\n",
        "length_long_sentence = len(word_tokenize(longest_sentence))\n",
        "\n",
        "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\n",
        "\n",
        "print(padded_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[14  3 15 16  1  0  0]\n",
            " [ 4 17  6  9  5  7  2]\n",
            " [18 19 20  2  3 21  0]\n",
            " [22 23  0  0  0  0  0]\n",
            " [24 25 26 27  5  7  2]\n",
            " [28  8  9 29  0  0  0]\n",
            " [30 31 32  8 33  1  0]\n",
            " [ 2  3  8 34  1  0  0]\n",
            " [10 11  0  0  0  0  0]\n",
            " [35 36 37  0  0  0  0]\n",
            " [12 38  0  0  0  0  0]\n",
            " [ 2  6 39 40  0  0  0]\n",
            " [ 5 41 13  7  4  1  0]\n",
            " [ 4  1  6 10  0  0  0]\n",
            " [ 5 42 13 43  0  0  0]\n",
            " [ 4 11  3 12  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwOug0Pnexjf"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('glove_wiki_id_50.txt', encoding=\"utf8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1jNMtaXfFCM"
      },
      "source": [
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "\n",
        "glove_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLtcctI1a3Io"
      },
      "source": [
        "embedding_matrix = zeros((vocab_length, 50))\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpC1T1kpd1fH"
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(vocab_length, 50, weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40HGhtPga6Zn",
        "outputId": "ce929ee2-b290-44a3-f243-4e24fd0bdb4c"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_21 (Embedding)     (None, 7, 50)             2200      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 350)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 351       \n",
            "=================================================================\n",
            "Total params: 2,551\n",
            "Trainable params: 351\n",
            "Non-trainable params: 2,200\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD8kiu7OgIfl",
        "outputId": "5ee42d80-61ec-45bb-9318-7cfe4cf50ea4"
      },
      "source": [
        "model.fit(padded_sentences, sentiments, epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6979 - acc: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6957 - acc: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6936 - acc: 0.5625\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6914 - acc: 0.5625\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6893 - acc: 0.5625\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6872 - acc: 0.5625\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6851 - acc: 0.5625\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6830 - acc: 0.5625\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6809 - acc: 0.5625\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6788 - acc: 0.6250\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6768 - acc: 0.7500\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6747 - acc: 0.8750\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6727 - acc: 0.8125\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6706 - acc: 0.8125\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6686 - acc: 0.8125\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6666 - acc: 0.8125\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6646 - acc: 0.8125\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6626 - acc: 0.8125\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6607 - acc: 0.8125\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6587 - acc: 0.8125\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6568 - acc: 0.8125\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6548 - acc: 0.8125\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6529 - acc: 0.8125\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6510 - acc: 0.8125\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6491 - acc: 0.8125\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6472 - acc: 0.8125\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6453 - acc: 0.8125\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6435 - acc: 0.8125\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6416 - acc: 0.8125\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6397 - acc: 0.8125\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6379 - acc: 0.8125\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6361 - acc: 0.8125\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6343 - acc: 0.8125\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6325 - acc: 0.8125\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6307 - acc: 0.8125\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6289 - acc: 0.8125\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6271 - acc: 0.8125\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6254 - acc: 0.8125\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6236 - acc: 0.8125\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6219 - acc: 0.8125\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6201 - acc: 0.8125\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6184 - acc: 0.8125\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6167 - acc: 0.8125\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6150 - acc: 0.8125\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6133 - acc: 0.8750\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6116 - acc: 0.8750\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6099 - acc: 0.8750\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6082 - acc: 0.8750\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6066 - acc: 0.8750\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6049 - acc: 0.8750\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6033 - acc: 0.8750\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6016 - acc: 0.8750\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6000 - acc: 0.8750\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5984 - acc: 0.8750\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5968 - acc: 0.8750\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5952 - acc: 0.9375\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5936 - acc: 0.9375\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5920 - acc: 0.9375\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5904 - acc: 0.9375\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5888 - acc: 0.9375\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5873 - acc: 0.9375\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5857 - acc: 0.9375\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5842 - acc: 0.9375\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5826 - acc: 0.9375\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5811 - acc: 0.9375\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5796 - acc: 0.9375\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5781 - acc: 0.9375\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5765 - acc: 0.9375\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5750 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5736 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5721 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5706 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5691 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5677 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5662 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5648 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5633 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5619 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5605 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5590 - acc: 0.9375\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5576 - acc: 0.9375\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5562 - acc: 0.9375\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5548 - acc: 0.9375\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5534 - acc: 0.9375\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5520 - acc: 0.9375\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5507 - acc: 0.9375\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5493 - acc: 0.9375\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5479 - acc: 0.9375\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5466 - acc: 0.9375\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5452 - acc: 0.9375\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5439 - acc: 0.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5425 - acc: 0.9375\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5412 - acc: 0.9375\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5399 - acc: 0.9375\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5386 - acc: 0.9375\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5373 - acc: 0.9375\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5359 - acc: 0.9375\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5346 - acc: 0.9375\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5334 - acc: 0.9375\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5321 - acc: 0.9375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f956e16c150>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dEB-bUdgRf4",
        "outputId": "d6788804-5af1-4670-d2b3-88321363078b"
      },
      "source": [
        "loss, accuracy = model.evaluate(padded_sentences, sentiments, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.750000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aIFbWOPgV2g"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "\n",
        "deep_inputs = Input(shape=(length_long_sentence,))\n",
        "embedding = Embedding(vocab_length, 50, weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)(deep_inputs) # line A\n",
        "flatten = Flatten()(embedding)\n",
        "hidden = Dense(1, activation='sigmoid')(flatten)\n",
        "model = Model(inputs=deep_inputs, outputs=hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvJcJYRKgZWC",
        "outputId": "3aac27e4-6a82-47b2-967c-0a59a30f2efb"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 7)]               0         \n",
            "_________________________________________________________________\n",
            "embedding_23 (Embedding)     (None, 7, 50)             2200      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 350)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 351       \n",
            "=================================================================\n",
            "Total params: 2,551\n",
            "Trainable params: 351\n",
            "Non-trainable params: 2,200\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh6i9jdpgfjo",
        "outputId": "b6483783-8e53-48e5-862c-43e5989e2ee6"
      },
      "source": [
        "model.fit(padded_sentences, sentiments, epochs=100, verbose=1)\n",
        "loss, accuracy = model.evaluate(padded_sentences, sentiments, verbose=0)\n",
        "\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.6809 - acc: 0.6875\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6788 - acc: 0.6875\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6768 - acc: 0.6875\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6747 - acc: 0.6875\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6727 - acc: 0.6875\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6706 - acc: 0.8125\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6686 - acc: 0.8125\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6666 - acc: 0.8125\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6646 - acc: 0.8125\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6626 - acc: 0.8125\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6606 - acc: 0.8125\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6587 - acc: 0.8125\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6567 - acc: 0.8125\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6548 - acc: 0.8125\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6528 - acc: 0.8125\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6509 - acc: 0.8125\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6489 - acc: 0.8125\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6470 - acc: 0.8125\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6451 - acc: 0.8750\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6432 - acc: 0.8750\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6413 - acc: 0.8750\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6395 - acc: 0.8750\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6376 - acc: 0.8750\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6357 - acc: 0.8750\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6339 - acc: 0.8750\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6320 - acc: 0.8750\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6302 - acc: 0.8750\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6284 - acc: 0.8750\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6266 - acc: 0.8750\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6248 - acc: 0.8750\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6230 - acc: 0.8750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6212 - acc: 0.8750\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6194 - acc: 0.8750\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6176 - acc: 0.8750\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6159 - acc: 0.8750\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6141 - acc: 0.8750\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6124 - acc: 0.8750\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6107 - acc: 0.8750\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6090 - acc: 0.8750\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6073 - acc: 0.9375\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6056 - acc: 0.9375\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6039 - acc: 0.9375\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6022 - acc: 0.9375\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6005 - acc: 0.9375\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5988 - acc: 0.9375\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5972 - acc: 0.9375\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5955 - acc: 0.9375\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5939 - acc: 0.9375\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5923 - acc: 0.9375\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5907 - acc: 0.9375\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5891 - acc: 0.9375\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5874 - acc: 0.9375\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5859 - acc: 0.9375\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5843 - acc: 0.9375\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5827 - acc: 0.9375\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5811 - acc: 0.8750\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5796 - acc: 0.8750\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5780 - acc: 0.8750\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5765 - acc: 0.8750\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5749 - acc: 0.8750\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5734 - acc: 0.8750\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5719 - acc: 0.8750\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5704 - acc: 0.8750\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5689 - acc: 0.8750\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5674 - acc: 0.8750\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5659 - acc: 0.8750\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5644 - acc: 0.8750\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5630 - acc: 0.8750\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5615 - acc: 0.8750\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5600 - acc: 0.8750\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5586 - acc: 0.8750\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5572 - acc: 0.8750\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5557 - acc: 0.8750\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5543 - acc: 0.8750\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5529 - acc: 0.8750\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5515 - acc: 0.8750\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5501 - acc: 0.8750\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5487 - acc: 0.8750\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5473 - acc: 0.8750\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5459 - acc: 0.8750\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5445 - acc: 0.8750\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5432 - acc: 0.8750\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5418 - acc: 0.8750\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5405 - acc: 0.8750\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5391 - acc: 0.8750\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5378 - acc: 0.8750\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5364 - acc: 0.8750\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5351 - acc: 0.8750\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5338 - acc: 0.8750\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5325 - acc: 0.8750\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5312 - acc: 0.8750\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5299 - acc: 0.8750\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5286 - acc: 0.8750\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5273 - acc: 0.8750\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5260 - acc: 0.8750\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5248 - acc: 0.8750\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5235 - acc: 0.8750\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5222 - acc: 0.8750\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5210 - acc: 0.8750\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5197 - acc: 0.8750\n",
            "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9567f6a5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Accuracy: 87.500000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7gu5AABgjJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1492ce96-0b3d-4ce2-aff1-75df42463aaa"
      },
      "source": [
        "print(embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.078951    0.147156   -0.03935    ... -0.025625    0.053181\n",
            "   0.012908  ]\n",
            " [ 0.105143   -0.211925    0.011668   ... -0.067152    0.14919201\n",
            "  -0.19564   ]\n",
            " ...\n",
            " [ 0.095798    0.003681    0.077189   ...  0.030864    0.00545\n",
            "  -0.014658  ]\n",
            " [ 0.051755   -0.023189   -0.069458   ... -0.005546    0.052251\n",
            "  -0.060099  ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_jxygBZgnIr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}