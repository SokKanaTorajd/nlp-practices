{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a25c4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4682cf40",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1cf8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_chars(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "def count_capital_chars(text):\n",
    "    count=0\n",
    "    for i in text:\n",
    "        if i.isupper():\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "def count_capital_words(text):\n",
    "    return sum(map(str.isupper,text.split()))\n",
    "\n",
    "\n",
    "def count_punctuations(text):\n",
    "    punctuations= string.punctuation\n",
    "    d=dict()\n",
    "    for i in punctuations:\n",
    "        d[str(i)+' count']=text.count(i)\n",
    "    return d \n",
    "\n",
    "\n",
    "# def count_words_in_quotes(text):\n",
    "#     x = re.findall(\"'.'|\".\"\", text)\n",
    "#     count=0\n",
    "#     if x is None:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         for i in x:\n",
    "#             t=i[1:-1]\n",
    "#             count+=count_words(t)\n",
    "#         return count\n",
    "    \n",
    "\n",
    "def count_sent(text):\n",
    "    return len(nltk.sent_tokenize(text))\n",
    "\n",
    "\n",
    "def count_unique_words(text):\n",
    "    return len(set(text.split()))\n",
    "\n",
    "\n",
    "def count_htags(text):\n",
    "    x = re.findall(r'(#w[A-Za-z0-9]*)', text)\n",
    "    return len(x) \n",
    "\n",
    "\n",
    "def count_mentions(text):\n",
    "    x = re.findall(r'(@w[A-Za-z0-9]*)', text)\n",
    "    return len(x)\n",
    "\n",
    "\n",
    "def count_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))  \n",
    "    word_tokens = word_tokenize(text)\n",
    "    stopwords_x = [w for w in word_tokens if w in stop_words]\n",
    "    return len(stopwords_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8666297",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/Users/fttiunjani/gemastik/practice/dataset/dataset-idsa-master/labelled-sentiment-copy.csv'\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16996a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimen</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>lagu bosan apa yang aku save ni huhuhuhuhuhuhu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>kita lanjutkan saja diam ini hingga kau dan ak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>doa rezeki tak putus inna haa zaa larizquna ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>makasih loh ntar kita bagi hasil aku 99 9 sisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>aku tak faham betul jenis orang malaysia yang ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentimen                                              Tweet\n",
       "0        -1  lagu bosan apa yang aku save ni huhuhuhuhuhuhu...\n",
       "1        -1  kita lanjutkan saja diam ini hingga kau dan ak...\n",
       "2         1  doa rezeki tak putus inna haa zaa larizquna ma...\n",
       "3         1  makasih loh ntar kita bagi hasil aku 99 9 sisa...\n",
       "4        -1  aku tak faham betul jenis orang malaysia yang ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef65432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10806 entries, 0 to 10805\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentimen  10806 non-null  int64 \n",
      " 1   Tweet     10806 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 169.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "320ca1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['char_count'] = df[\"Tweet\"].apply(lambda x:count_chars(x))\n",
    "df['word_count'] = df[\"Tweet\"].apply(lambda x:count_words(x))\n",
    "df['sent_count'] = df[\"Tweet\"].apply(lambda x:count_sent(x))\n",
    "df['capital_char_count'] = df[\"Tweet\"].apply(lambda x:count_capital_chars(x))\n",
    "df['capital_word_count'] = df[\"Tweet\"].apply(lambda x:count_capital_words(x))\n",
    "# df['quoted_word_count'] = df[\"tweet\"].apply(lambda x:count_words_in_quotes(x))\n",
    "df['stopword_count'] = df[\"Tweet\"].apply(lambda x:count_stopwords(x))\n",
    "df['unique_word_count'] = df[\"Tweet\"].apply(lambda x:count_unique_words(x))\n",
    "df['htag_count'] = df[\"Tweet\"].apply(lambda x:count_htags(x))\n",
    "df['mention_count'] = df[\"Tweet\"].apply(lambda x:count_mentions(x))\n",
    "df['punct_count'] = df[\"Tweet\"].apply(lambda x:count_punctuations(x))\n",
    "df['avg_wordlength'] = df['char_count']/df['word_count']\n",
    "df['avg_sentlength'] = df['word_count']/df['sent_count']\n",
    "df['unique_vs_words'] = df['unique_word_count']/df['word_count']\n",
    "df['stopwords_vs_words'] = df['stopword_count']/df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d558cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating average word length\n",
    "df['avg_wordlength'] = df['char_count']/df['word_count']\n",
    "\n",
    "# Calculating average sentence length\n",
    "df['avg_sentlength'] = df['word_count']/df['sent_count']\n",
    "\n",
    "# unique words vs word count feature\n",
    "df['unique_vs_words'] = df['unique_word_count']/df['word_count']\n",
    "\n",
    "# Stopwords count vs words counts feature\n",
    "df['stopwords_vs_words'] = df['stopword_count']/df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59907929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimen</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_char_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>htag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>avg_sentlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>lagu bosan apa yang aku save ni huhuhuhuhuhuhu...</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>kita lanjutkan saja diam ini hingga kau dan ak...</td>\n",
       "      <td>103</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.437500</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>doa rezeki tak putus inna haa zaa larizquna ma...</td>\n",
       "      <td>114</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>makasih loh ntar kita bagi hasil aku 99 9 sisa...</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>aku tak faham betul jenis orang malaysia yang ...</td>\n",
       "      <td>107</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentimen                                              Tweet  char_count  \\\n",
       "0        -1  lagu bosan apa yang aku save ni huhuhuhuhuhuhu...          65   \n",
       "1        -1  kita lanjutkan saja diam ini hingga kau dan ak...         103   \n",
       "2         1  doa rezeki tak putus inna haa zaa larizquna ma...         114   \n",
       "3         1  makasih loh ntar kita bagi hasil aku 99 9 sisa...          59   \n",
       "4        -1  aku tak faham betul jenis orang malaysia yang ...         107   \n",
       "\n",
       "   word_count  sent_count  capital_char_count  capital_word_count  \\\n",
       "0           8           1                   0                   0   \n",
       "1          16           1                   0                   0   \n",
       "2          20           1                   0                   0   \n",
       "3          12           1                   0                   0   \n",
       "4          20           1                   0                   0   \n",
       "\n",
       "   stopword_count  unique_word_count  htag_count  mention_count  \\\n",
       "0               0                  8           0              0   \n",
       "1               0                 16           0              0   \n",
       "2               0                 20           0              0   \n",
       "3               0                 12           0              0   \n",
       "4               0                 17           0              0   \n",
       "\n",
       "                                         punct_count  avg_wordlength  \\\n",
       "0  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        8.125000   \n",
       "1  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.437500   \n",
       "2  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        5.700000   \n",
       "3  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        4.916667   \n",
       "4  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        5.350000   \n",
       "\n",
       "   avg_sentlength  unique_vs_words  stopwords_vs_words  \n",
       "0             8.0             1.00                 0.0  \n",
       "1            16.0             1.00                 0.0  \n",
       "2            20.0             1.00                 0.0  \n",
       "3            12.0             1.00                 0.0  \n",
       "4            20.0             0.85                 0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "553bb8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimen</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_char_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>htag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>avg_sentlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negatif</td>\n",
       "      <td>agu bosan apa yang aku save ni huhuhuhuhuhuhuh...</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negatif</td>\n",
       "      <td>ta lanjutkan saja diam ini hingga kau dan aku ...</td>\n",
       "      <td>103</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.437500</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positif</td>\n",
       "      <td>doa rezeki tak putus inna haa zaa larizquna ma...</td>\n",
       "      <td>114</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positif</td>\n",
       "      <td>makasih loh ntar kita bagi hasil aku   sisanya...</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negatif</td>\n",
       "      <td>aku tak faham betul jenis orang malaysia yang ...</td>\n",
       "      <td>107</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentimen                                              Tweet  char_count  \\\n",
       "0  negatif  agu bosan apa yang aku save ni huhuhuhuhuhuhuh...          65   \n",
       "1  negatif  ta lanjutkan saja diam ini hingga kau dan aku ...         103   \n",
       "2  positif  doa rezeki tak putus inna haa zaa larizquna ma...         114   \n",
       "3  positif  makasih loh ntar kita bagi hasil aku   sisanya...          59   \n",
       "4  negatif  aku tak faham betul jenis orang malaysia yang ...         107   \n",
       "\n",
       "   word_count  sent_count  capital_char_count  capital_word_count  \\\n",
       "0           8           1                   0                   0   \n",
       "1          16           1                   0                   0   \n",
       "2          20           1                   0                   0   \n",
       "3          12           1                   0                   0   \n",
       "4          20           1                   0                   0   \n",
       "\n",
       "   stopword_count  unique_word_count  htag_count  mention_count  \\\n",
       "0               0                  8           0              0   \n",
       "1               0                 16           0              0   \n",
       "2               0                 20           0              0   \n",
       "3               0                 12           0              0   \n",
       "4               0                 17           0              0   \n",
       "\n",
       "                                         punct_count  avg_wordlength  \\\n",
       "0  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        8.125000   \n",
       "1  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.437500   \n",
       "2  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        5.700000   \n",
       "3  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        4.916667   \n",
       "4  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        5.350000   \n",
       "\n",
       "   avg_sentlength  unique_vs_words  stopwords_vs_words  \n",
       "0             8.0             1.00                 0.0  \n",
       "1            16.0             1.00                 0.0  \n",
       "2            20.0             1.00                 0.0  \n",
       "3            12.0             1.00                 0.0  \n",
       "4            20.0             0.85                 0.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replace = dict(zip([-1, 0, 1],['negatif', 'netral', 'positif']))\n",
    "df.replace({'sentimen':to_replace}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c4183de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Pre-processing \n",
    "def remove_links(tweet):\n",
    "    '''Takes a string and removes web links from it'''\n",
    "    tweet = re.sub(r'http\\S+', '', tweet) # remove http links\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', tweet) # rempve bitly links\n",
    "    tweet = tweet.strip('[link]') # remove [links]\n",
    "    return tweet\n",
    "\n",
    "def remove_users(tweet):\n",
    "    '''Takes a string and removes retweet and @user information'''\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove retweet\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
    "    return tweet\n",
    "\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "def preprocess(sent):\n",
    "    sent = remove_users(sent)\n",
    "    sent = remove_links(sent)\n",
    "    sent = sent.lower() # lower case\n",
    "    sent = re.sub('['+my_punctuation + ']+', ' ', sent) # strip punctuation\n",
    "    sent = re.sub('\\s+', ' ', sent) #remove double spacing\n",
    "    sent = re.sub('([0-9]+)', '', sent) # remove numbers\n",
    "    sent_token_list = [word for word in sent.split(' ')]\n",
    "    sent = ' '.join(sent_token_list)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64869311",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Tweet = df.Tweet.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cabd513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10806, 22123)\n"
     ]
    }
   ],
   "source": [
    "# Using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorized = vectorizer.fit_transform(df['Tweet']).toarray()\n",
    "print(vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb9d7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71dd9660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22113</th>\n",
       "      <th>22114</th>\n",
       "      <th>22115</th>\n",
       "      <th>22116</th>\n",
       "      <th>22117</th>\n",
       "      <th>22118</th>\n",
       "      <th>22119</th>\n",
       "      <th>22120</th>\n",
       "      <th>22121</th>\n",
       "      <th>22122</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10804</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10805</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10806 rows × 22123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9      \\\n",
       "0        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "10801    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10802    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10803    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10804    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10805    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       ...  22113  22114  22115  22116  22117  22118  22119  22120  22121  \\\n",
       "0      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "10801  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10802  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10803  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10804  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "10805  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       22122  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "...      ...  \n",
       "10801    0.0  \n",
       "10802    0.0  \n",
       "10803    0.0  \n",
       "10804    0.0  \n",
       "10805    0.0  \n",
       "\n",
       "[10806 rows x 22123 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ce2795c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['char_count',\n",
       " 'word_count',\n",
       " 'sent_count',\n",
       " 'capital_char_count',\n",
       " 'capital_word_count',\n",
       " 'stopword_count',\n",
       " 'unique_word_count',\n",
       " 'htag_count',\n",
       " 'mention_count',\n",
       " 'avg_wordlength',\n",
       " 'avg_sentlength',\n",
       " 'unique_vs_words',\n",
       " 'stopwords_vs_words']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [feature for feature in df.columns if feature !='Tweet' and feature !='sentimen' and feature != 'punct_count']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1aeeef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(df_tfidf, df[features], left_index=True, right_index=True)\n",
    "y = df['sentimen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f03ad0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>capital_char_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>htag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>avg_sentlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.437500</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  capital_char_count  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...                   0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...                   0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...                   0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...                   0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...                   0   \n",
       "\n",
       "   capital_word_count  stopword_count  unique_word_count  htag_count  \\\n",
       "0                   0               0                  8           0   \n",
       "1                   0               0                 16           0   \n",
       "2                   0               0                 20           0   \n",
       "3                   0               0                 12           0   \n",
       "4                   0               0                 17           0   \n",
       "\n",
       "   mention_count  avg_wordlength  avg_sentlength  unique_vs_words  \\\n",
       "0              0        8.125000             8.0             1.00   \n",
       "1              0        6.437500            16.0             1.00   \n",
       "2              0        5.700000            20.0             1.00   \n",
       "3              0        4.916667            12.0             1.00   \n",
       "4              0        5.350000            20.0             0.85   \n",
       "\n",
       "   stopwords_vs_words  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "\n",
       "[5 rows x 22136 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82b04d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17de7406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8644 entries, 4940 to 3582\n",
      "Columns: 22131 entries, 0 to stopwords_vs_words\n",
      "dtypes: float64(22122), int64(9)\n",
      "memory usage: 1.4 GB\n"
     ]
    }
   ],
   "source": [
    "type(X_train)\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e69a8806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet length for train = 8644, sentimen length for train = 8644\n",
      "tweet length for test = 2162, sentimen length for train = 2162\n"
     ]
    }
   ],
   "source": [
    "print(f'tweet length for train = {len(X_train)}, sentimen length for train = {len(y_train)}')\n",
    "print(f'tweet length for test = {len(X_test)}, sentimen length for train = {len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e9e7e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators = 1000, min_samples_split = 15, random_state = 42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_prediction = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7fe7955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =>  56.34\n",
      "\n",
      "Random Forest Classifier results: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.65      0.22      0.33       569\n",
      "      netral       0.55      0.91      0.69      1068\n",
      "     positif       0.60      0.24      0.34       525\n",
      "\n",
      "    accuracy                           0.56      2162\n",
      "   macro avg       0.60      0.45      0.45      2162\n",
      "weighted avg       0.59      0.56      0.51      2162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy => \", round(accuracy_score(rf_prediction, y_test)*100, 2))\n",
    "print(\"\\nRandom Forest Classifier results: \\n\")\n",
    "print(classification_report(y_test, rf_prediction, target_names = ['negatif', 'netral', 'positif']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b4f4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a660a722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_sentimen_classifier.joblib']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "joblib.dump(rf_classifier, \"random_forest_sentimen_classifier.joblib\")\n",
    "\n",
    "# load\n",
    "# loaded_rf = joblib.load(\"my_random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2bdb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
